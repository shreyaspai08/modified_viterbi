{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(nltk_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and validation sets in 95:5 ratio\n",
    "random.seed(1234)\n",
    "train_set, val_set = train_test_split(nltk_data, train_size=0.95, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3718"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95589\n",
      "[('Bank', 'NOUN'), ('of', 'ADP'), ('New', 'NOUN'), ('England', 'NOUN'), (\"'s\", 'PRT')]\n"
     ]
    }
   ],
   "source": [
    "#Creating a list of all (word, tag) tuples\n",
    "train_tagged_words = [ word_tag_tup for sent in train_set for word_tag_tup in sent ]\n",
    "\n",
    "print(len(train_tagged_words))\n",
    "print(train_tagged_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN', 'ADP', 'NOUN', 'NOUN', 'PRT', 'NOUN', 'VERB', 'VERB', 'X', 'ADP']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_in_data = [tup[1] for tup in train_tagged_words]\n",
    "tags_in_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing unique tags in the set\n",
    "unique_tags = set(tags_in_data)\n",
    "print(len(unique_tags))\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_tag(word, tag, train_data=train_tagged_words):\n",
    "    #Getting pairs where tags = 'tag'\n",
    "    word_tag_list = [tup for tup in train_data if tup[1] == tag]\n",
    "    #Getting list of word_tag_list pairs for 'word'\n",
    "    words_given_tag = [tup for tup in word_tag_list if tup[0] == word]\n",
    "    return len(words_given_tag)/len(word_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For transmission probabilities in 'tags_in_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'tags_in_data' is the list of all train tags\n",
    "total_tag_count = len(tags_in_data)\n",
    "\n",
    "def tag2_given_tag1(tag2, tag1):\n",
    "    #Getting list of tags = 'tag1'\n",
    "    tag1_list = [tag for tag in tags_in_data if tag == tag1]\n",
    "    #Getting list of tag1_list pairs for 'word'\n",
    "    count_tag1 = len(tag1_list)\n",
    "    \n",
    "    count_tag2_given_tag1 = 0\n",
    "    for i,tag in enumerate(tags_in_data):\n",
    "        if i+1<total_tag_count and tags_in_data[i+1] == tag2 and tag==tag1:\n",
    "            count_tag2_given_tag1+=1\n",
    "        \n",
    "    return count_tag2_given_tag1/count_tag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tags_matrix such that tags_matrix[i][j] has value of P(tj given ti) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = np.zeros((len(unique_tags),len(unique_tags)), dtype='float32')\n",
    "\n",
    "for i, t1 in enumerate(unique_tags):\n",
    "    for j, t2 in enumerate(unique_tags):\n",
    "        tags_matrix[i][j] = tag2_given_tag1(t2, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.02139007e-03, 7.48663098e-02, 4.96562244e-03, 3.39954160e-02,\n",
       "        1.22230714e-02, 7.25744851e-03, 9.54927411e-03, 4.80901450e-01,\n",
       "        2.29182579e-02, 9.28189456e-02, 4.12528664e-02, 2.11229950e-01],\n",
       "       [6.58219506e-04, 6.66447282e-02, 1.69491526e-02, 4.60753683e-03,\n",
       "        1.08606219e-02, 2.04048045e-02, 5.10120112e-03, 1.23416157e-02,\n",
       "        7.89863393e-02, 2.13921349e-02, 6.53282851e-02, 6.96725368e-01],\n",
       "       [5.86579069e-02, 1.16846554e-01, 4.69263265e-04, 5.58423288e-02,\n",
       "        4.69263270e-03, 4.22336943e-02, 1.21539183e-01, 1.53918341e-01,\n",
       "        5.44345379e-02, 7.97747541e-03, 3.42562161e-02, 3.49131852e-01],\n",
       "       [1.56146176e-02, 1.30232558e-01, 6.31229253e-03, 8.10631216e-02,\n",
       "        1.36212623e-02, 3.05647831e-02, 6.71096370e-02, 3.44518274e-01,\n",
       "        1.19601332e-01, 2.35880390e-02, 1.36877075e-01, 3.08970101e-02],\n",
       "       [1.89604443e-02, 8.63027126e-02, 2.28832942e-03, 1.01340311e-02,\n",
       "        1.63452106e-03, 5.85158542e-02, 1.00359596e-01, 4.02745992e-01,\n",
       "        2.15756781e-02, 1.34030730e-02, 4.15168367e-02, 2.42562935e-01],\n",
       "       [1.48676778e-03, 3.41956578e-02, 1.33809103e-02, 2.97353556e-03,\n",
       "        2.79512331e-02, 1.84061855e-01, 3.27088917e-03, 1.75438598e-02,\n",
       "        3.47903669e-02, 2.06660718e-01, 1.18346713e-01, 3.55337501e-01],\n",
       "       [3.74215352e-03, 2.04973444e-01, 4.82858537e-04, 1.23128919e-02,\n",
       "        2.41429268e-04, 2.19700634e-02, 5.31144394e-03, 3.83872539e-02,\n",
       "        9.05359723e-03, 4.55094166e-02, 1.79864801e-02, 6.40028954e-01],\n",
       "       [3.62436958e-02, 6.46488145e-02, 5.58789307e-03, 8.25766400e-02,\n",
       "        3.11214589e-02, 2.28172299e-02, 1.33100510e-01, 1.69188976e-01,\n",
       "        9.04928222e-02, 2.18005434e-01, 3.53123769e-02, 1.10904150e-01],\n",
       "       [6.91278726e-02, 1.05296947e-01, 8.56072758e-04, 1.31621184e-02,\n",
       "        1.49812736e-03, 6.29213452e-02, 3.26377749e-01, 8.23970046e-03,\n",
       "        1.72284637e-02, 3.40288915e-02, 3.94863561e-02, 3.21776360e-01],\n",
       "       [5.60866781e-02, 1.65710635e-02, 1.03569152e-02, 2.51752716e-02,\n",
       "        1.85787126e-01, 2.70873168e-03, 5.51306568e-02, 2.03632891e-01,\n",
       "        1.42925426e-01, 7.64818341e-02, 1.63798600e-01, 6.13448061e-02],\n",
       "       [6.53894618e-02, 4.49721180e-02, 5.79240881e-02, 5.20777106e-02,\n",
       "        2.33855005e-03, 8.05000886e-02, 1.73502430e-01, 8.85051265e-02,\n",
       "        9.11135077e-02, 2.66234931e-02, 9.38118398e-02, 2.23151639e-01],\n",
       "       [4.92287474e-03, 1.22889541e-02, 4.19356003e-02, 1.68836378e-02,\n",
       "        4.38318215e-02, 9.62695573e-03, 1.33099956e-02, 1.47977978e-01,\n",
       "        1.76275387e-01, 2.91361269e-02, 2.39178792e-01, 2.64631867e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a DataFrame of tags as columns and rows with values as transmission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(tags_matrix, columns=unique_tags, index=unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>DET</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADP</th>\n",
       "      <th>X</th>\n",
       "      <th>.</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.074866</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.480901</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.092819</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.211230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.066645</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.020405</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.078986</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>0.065328</td>\n",
       "      <td>0.696725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.058658</td>\n",
       "      <td>0.116847</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.055842</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.042234</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>0.153918</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.034256</td>\n",
       "      <td>0.349132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.130233</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.081063</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.067110</td>\n",
       "      <td>0.344518</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.023588</td>\n",
       "      <td>0.136877</td>\n",
       "      <td>0.030897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.086303</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.058516</td>\n",
       "      <td>0.100360</td>\n",
       "      <td>0.402746</td>\n",
       "      <td>0.021576</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.041517</td>\n",
       "      <td>0.242563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.034196</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>0.184062</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>0.206661</td>\n",
       "      <td>0.118347</td>\n",
       "      <td>0.355338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.204973</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.038387</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.045509</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.640029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.036244</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.082577</td>\n",
       "      <td>0.031121</td>\n",
       "      <td>0.022817</td>\n",
       "      <td>0.133101</td>\n",
       "      <td>0.169189</td>\n",
       "      <td>0.090493</td>\n",
       "      <td>0.218005</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>0.110904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.069128</td>\n",
       "      <td>0.105297</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.062921</td>\n",
       "      <td>0.326378</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>0.034029</td>\n",
       "      <td>0.039486</td>\n",
       "      <td>0.321776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.056087</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.185787</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.055131</td>\n",
       "      <td>0.203633</td>\n",
       "      <td>0.142925</td>\n",
       "      <td>0.076482</td>\n",
       "      <td>0.163799</td>\n",
       "      <td>0.061345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.065389</td>\n",
       "      <td>0.044972</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.052078</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.173502</td>\n",
       "      <td>0.088505</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>0.026623</td>\n",
       "      <td>0.093812</td>\n",
       "      <td>0.223152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.041936</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.147978</td>\n",
       "      <td>0.176275</td>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.239179</td>\n",
       "      <td>0.264632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PRON       ADJ      CONJ       ADV       PRT       NUM       DET  \\\n",
       "PRON  0.008021  0.074866  0.004966  0.033995  0.012223  0.007257  0.009549   \n",
       "ADJ   0.000658  0.066645  0.016949  0.004608  0.010861  0.020405  0.005101   \n",
       "CONJ  0.058658  0.116847  0.000469  0.055842  0.004693  0.042234  0.121539   \n",
       "ADV   0.015615  0.130233  0.006312  0.081063  0.013621  0.030565  0.067110   \n",
       "PRT   0.018960  0.086303  0.002288  0.010134  0.001635  0.058516  0.100360   \n",
       "NUM   0.001487  0.034196  0.013381  0.002974  0.027951  0.184062  0.003271   \n",
       "DET   0.003742  0.204973  0.000483  0.012313  0.000241  0.021970  0.005311   \n",
       "VERB  0.036244  0.064649  0.005588  0.082577  0.031121  0.022817  0.133101   \n",
       "ADP   0.069128  0.105297  0.000856  0.013162  0.001498  0.062921  0.326378   \n",
       "X     0.056087  0.016571  0.010357  0.025175  0.185787  0.002709  0.055131   \n",
       ".     0.065389  0.044972  0.057924  0.052078  0.002339  0.080500  0.173502   \n",
       "NOUN  0.004923  0.012289  0.041936  0.016884  0.043832  0.009627  0.013310   \n",
       "\n",
       "          VERB       ADP         X         .      NOUN  \n",
       "PRON  0.480901  0.022918  0.092819  0.041253  0.211230  \n",
       "ADJ   0.012342  0.078986  0.021392  0.065328  0.696725  \n",
       "CONJ  0.153918  0.054435  0.007977  0.034256  0.349132  \n",
       "ADV   0.344518  0.119601  0.023588  0.136877  0.030897  \n",
       "PRT   0.402746  0.021576  0.013403  0.041517  0.242563  \n",
       "NUM   0.017544  0.034790  0.206661  0.118347  0.355338  \n",
       "DET   0.038387  0.009054  0.045509  0.017986  0.640029  \n",
       "VERB  0.169189  0.090493  0.218005  0.035312  0.110904  \n",
       "ADP   0.008240  0.017228  0.034029  0.039486  0.321776  \n",
       "X     0.203633  0.142925  0.076482  0.163799  0.061345  \n",
       ".     0.088505  0.091114  0.026623  0.093812  0.223152  \n",
       "NOUN  0.147978  0.176275  0.029136  0.239179  0.264632  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            emission_p = word_given_tag(word, tag)\n",
    "            \n",
    "            # compute emission and state probabilities\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('For', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Agency', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('International', 'NOUN'),\n",
       " ('Development', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('appropriators', 'NOUN'),\n",
       " ('approved', 'VERB'),\n",
       " ('$', '.'),\n",
       " ('200', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('secondary', 'ADJ'),\n",
       " ('loan', 'NOUN'),\n",
       " ('guarantees', 'NOUN'),\n",
       " ('under', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('expanded', 'VERB')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of (word, tags) in validation set\n",
    "val_run_base = [tup for sent in val_set for tup in sent]\n",
    "val_run_base[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For',\n",
       " 'the',\n",
       " 'Agency',\n",
       " 'for',\n",
       " 'International',\n",
       " 'Development',\n",
       " ',',\n",
       " 'appropriators',\n",
       " 'approved',\n",
       " '$']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a list of words from the validation set\n",
    "\n",
    "val_tagged_words = [tup[0] for sent in val_set for tup in sent]\n",
    "val_tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging words in the validation set using Vanilla Viterbi\n",
    "tagged_seq = Viterbi(val_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [i for i, j in zip(tagged_seq, val_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Vanilla Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9131118537448398"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check)/len(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of previous (word, tag), predicted and actual (word,tag) of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prev': ('expanded', 'VERB'),\n",
       "  'predicted': ('trade', 'VERB'),\n",
       "  'actual': ('trade', 'NOUN')},\n",
       " {'prev': ('the', 'DET'),\n",
       "  'predicted': ('Overseas', 'PRON'),\n",
       "  'actual': ('Overseas', 'NOUN')},\n",
       " {'prev': ('Overseas', 'NOUN'),\n",
       "  'predicted': ('Private', 'ADJ'),\n",
       "  'actual': ('Private', 'NOUN')},\n",
       " {'prev': ('settled', 'VERB'),\n",
       "  'predicted': ('pre-1917', 'PRON'),\n",
       "  'actual': ('pre-1917', 'ADJ')},\n",
       " {'prev': ('``', '.'),\n",
       "  'predicted': ('Unemployment', 'PRON'),\n",
       "  'actual': ('Unemployment', 'NOUN')},\n",
       " {'prev': ('the', 'DET'),\n",
       "  'predicted': ('purchasing', 'NOUN'),\n",
       "  'actual': ('purchasing', 'VERB')},\n",
       " {'prev': ('weekly', 'ADJ'),\n",
       "  'predicted': ('paycheck', 'PRON'),\n",
       "  'actual': ('paycheck', 'NOUN')},\n",
       " {'prev': ('paycheck', 'NOUN'),\n",
       "  'predicted': ('reasonably', 'PRON'),\n",
       "  'actual': ('reasonably', 'ADV')},\n",
       " {'prev': (',', '.'),\n",
       "  'predicted': ('though', 'ADP'),\n",
       "  'actual': ('though', 'ADV')},\n",
       " {'prev': ('such', 'ADJ'),\n",
       "  'predicted': ('close', 'NOUN'),\n",
       "  'actual': ('close', 'ADJ')}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [{ 'prev': val_run_base[i-1], 'predicted': j[0], 'actual': j[1]} for i, j in enumerate(zip(tagged_seq, val_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the incorrectly tagged words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word chain with '-' in them must be tagged as 'ADJ'\n",
    "#### Eg: 'American-style', 'cross-border', 'pre-existing'\n",
    "\n",
    "#### Words ending with 'ed' and 'ing' :VERB\n",
    "#### Eg: 'waived', 'shopped', 'alleged', 'indulging', 'apologizing'\n",
    "\n",
    "#### Words with digits in them decimal or non-decimal must be tagged as 'NUM'\n",
    "#### Eg: '1955', '133.7', '94'\n",
    "\n",
    "#### Words with '*-' in them must be tagged as 'X'\n",
    "#### Eg: '\\*T\\*-133 ', '\\*T\\*-253 ', '\\*-130 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VERB', 'PRON', 'ADJ', 'PRON', 'PRON', 'NOUN', 'PRON', 'PRON', 'ADP', 'NOUN']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrectly_assigned_tags = [obj['predicted'][1] for obj in incorrect_tagged_cases]\n",
    "incorrectly_assigned_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRON': 306,\n",
       " 'ADJ': 19,\n",
       " 'ADV': 17,\n",
       " 'CONJ': 1,\n",
       " 'PRT': 3,\n",
       " 'NUM': 3,\n",
       " 'DET': 3,\n",
       " 'VERB': 34,\n",
       " 'ADP': 21,\n",
       " 'NOUN': 35}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Occurences of each incorrectly assigned tags in Vanilla Viterbi\n",
    "freq_dist = { tag: incorrectly_assigned_tags.count(tag) for tag in set(incorrectly_assigned_tags)}\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the distribution, it is observed that the first tag 'ADP' in the set is assigned to an unknown word by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRON': 2618,\n",
       " 'ADJ': 6077,\n",
       " 'CONJ': 2131,\n",
       " 'ADV': 3010,\n",
       " 'PRT': 3059,\n",
       " 'NUM': 3363,\n",
       " 'DET': 8284,\n",
       " 'VERB': 12885,\n",
       " 'ADP': 9345,\n",
       " 'X': 6276,\n",
       " '.': 11118,\n",
       " 'NOUN': 27423}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_train = { tag: tags_in_data.count(tag) for tag in unique_tags}\n",
    "freq_dist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.6884474154976"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*(freq_dist_train['NOUN']/len(tags_in_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'NOUN' tag occurs the most at 28.68% in the train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving the problem of unknown words by tagging them as 'NOUN' instead of the fist tag in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic by tagging words as 'NOUN' for unknown words\n",
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            emission_p = word_given_tag(word, tag)\n",
    "            \n",
    "            # compute emission and state probabilities\n",
    "            state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        \n",
    "        if pmax == 0.0:\n",
    "            state_max = 'NOUN'            # For unknown words (state_probability=0), tagging them as 'NOUN' \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]  # getting state for which probability is maximum\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_iter1 = Viterbi_1(val_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "check1 = [i for i, j in zip(tagged_seq_iter1, val_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of modified Viterbi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9396500884607824"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check1)/len(tagged_seq_iter1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy increased from 91% to 93.96% \n",
    "#### Tagging unknown words with frequently occuring tag in the train helps in tagging correctly to an extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted by Vanilla Viterbi:\n",
    "#### 'predicted': ('protocols', 'ADP')\n",
    "#### 'actual': ('protocols', 'NOUN')\n",
    "\n",
    "\n",
    "#### 'predicted': ('Overseas', 'ADP')\n",
    "#### 'actual': ('Overseas', 'NOUN')\n",
    "\n",
    "\n",
    "#### 'predicted': ('paycheck', 'ADP')\n",
    "#### 'actual': ('paycheck', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted by Modification 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tag_given_word_from_output(word):\n",
    "    return [tup for tup in tagged_seq_iter1 if tup[0]==word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('protocols', 'NOUN')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('protocols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overseas', 'NOUN')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('Overseas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paycheck', 'NOUN')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('paycheck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So instead of getting tagged as the first occuring tag in the set,\n",
    "#### assigning the unkown words to most occuring tag, i.e 'NOUN' has helped fixing the tag assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out regex tagger as a backoff to the unknown words (whose state_probability is 0)\n",
    "#### Using the pattern found in incorrect_tagged_cases (from Vanilla Viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns=[\n",
    "    (r'\\d+.?\\d*$','NUM'),      # digits with or without decimals should be tagged as 'NUM'\n",
    "    (r'.*\\*-','X'),            # words with '*-' in them tagged as 'X'\n",
    "    (r'.*-.*','ADJ'),          # words with '-' in them, like '' are tagged 'ADJ'\n",
    "    (r'.*ing$|.*ed$','VERB')   # words ending with 'ing' and 'ed' are 'VERB'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegexpTagger initialised with patterns\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "# Viterbi Heuristic that tags words:\n",
    "#  1. Using Viterbi\n",
    "#  2. If state_probability is 0, then tags using RegexpTagger\n",
    "#  3. If even RegexpTagger can't find a tag to the word, tag it as 'NOUN' \n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            emission_p = word_given_tag(word, tag)\n",
    "            \n",
    "            # compute emission and state probabilities\n",
    "            state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = ''\n",
    "        if pmax != 0.0:\n",
    "            state_max = T[p.index(pmax)]\n",
    "        else:\n",
    "            state_max = regexp_tagger.tag([word])[0][1]\n",
    "        if not state_max:\n",
    "            state_max = 'NOUN'\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_iter2 = Viterbi_2(val_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "check2 = [i for i, j in zip(tagged_seq_iter2, val_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for the modified Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961666994299194"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check2)/len(tagged_seq_iter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy increased from 91% to 96.16%\n",
    "#### Tagging unknown words using RegexpTagger definitely helped\n",
    "#### Tagging unknown words with frequently occuring tag in the train set helps in tagging correctly to an extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted by Vanilla Viterbi:\n",
    "\n",
    "### NOUN\n",
    "#### 'predicted': ('protocols', 'ADP') => 'actual': ('protocols', 'NOUN')\n",
    "\n",
    "#### 'predicted': ('Overseas', 'ADP') => 'actual': ('Overseas', 'NOUN')\n",
    "\n",
    "### ADJ\n",
    "#### 'predicted': ('American-style', 'ADP') =>  'actual': ('American-style', 'ADJ')\n",
    "\n",
    "#### 'predicted': ('cross-border', 'ADP') =>  'actual': ('cross-border', 'ADJ')\n",
    "\n",
    "### VERB\n",
    "#### 'predicted': ('waived', 'ADP') =>  'actual': ('waived', 'VERB')\n",
    "\n",
    "#### 'predicted': ('shopped', 'ADP') =>  'actual': ('shopped', 'VERB')\n",
    "       \n",
    "#### 'predicted': ('indulging', 'ADP') =>  'actual': ('purchasing', 'VERB')\n",
    "\n",
    "#### 'predicted': ('apologizing', 'ADP') =>  'actual': ('apologizing', 'VERB')\n",
    "\n",
    "### NUM\n",
    "#### 'predicted': ('1955', 'ADP') =>  'actual': ('1955', 'NUM')\n",
    "\n",
    "#### 'predicted': ('133.7', 'ADP') =>  'actual': ('133.7', 'NUM')\n",
    "\n",
    "### X\n",
    "#### 'predicted': ('\\*T\\*-133', 'ADP') =>  'actual': ('\\*T\\*-133', 'X')\n",
    "\n",
    "#### 'predicted': ('\\*-130', 'ADP') =>  'actual': ('\\*-130', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted by Modification 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tag_given_word_from_output(word):\n",
    "    return [tup for tup in tagged_seq_iter2 if tup[0]==word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('protocols', 'NOUN')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('protocols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overseas', 'NOUN')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('Overseas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ADJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American-style', 'ADJ')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('American-style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cross-border', 'ADJ')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('cross-border')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('waived', 'VERB')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('waived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shopped', 'VERB')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('shopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indulging', 'VERB')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('indulging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apologizing', 'VERB')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('apologizing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1955', 'NUM')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('1955')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('133.7', 'NUM')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('133.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*T*-133', 'X')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('*T*-133')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*-130', 'X')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_tag_given_word_from_output('*-130')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('Test_sentences.txt')\n",
    "test_file_content=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Android is a mobile operating system developed by Google.\\nAndroid has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\\nGoogle and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\\nTwitter is an online news and social networking service on which users post and interact with messages known as tweets.\\nBefore entering politics, Donald Trump was a domineering businessman and a television personality.\\nThe 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\\nThis is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\\nShow me the cheapest round trips from Dallas to Atlanta\\nI would like to see flights from Denver to Philadelphia.\\nShow me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\\nNASA invited social media users to experience the launch of ICESAT-2 Satellite.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the text\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mobile',\n",
       " 'operating',\n",
       " 'system',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Google',\n",
       " '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = word_tokenize(test_file_content)\n",
    "test_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning tags to test sample using Vanilla Viterbi and the two modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanilla Viterbi\n",
    "tagged_test = Viterbi(test_words)\n",
    "\n",
    "#Modification 1\n",
    "tagged_test_1 = Viterbi_1(test_words)\n",
    "\n",
    "#Modification 2\n",
    "tagged_test_2 = Viterbi_2(test_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_test[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Android', 'Google' and 'Twitter' are tagged as 'ADP' should be a 'NOUN'\n",
    "\n",
    "#### '2013' and '2018' are tagged as 'ADP' should be a 'NUM'\n",
    "\n",
    "#### 'contested' is tagged as 'ADP' shuold be 'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions by Modification 1\n",
    "tagged_test_1[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Android', 'Google' and 'Twitter' are tagged as 'NOUN'\n",
    "\n",
    "#### But '2013' and '2018' are tagged as 'NOUN' should be a 'NUM'\n",
    "\n",
    "#### And 'contested' is tagged as 'NOUN' shuold be 'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions by Modification 2\n",
    "tagged_test_2[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Android', 'Google' and 'Twitter' are tagged correctly as 'NOUN'\n",
    "\n",
    "#### '2013' and '2018' are tagged correctly as 'NUM'\n",
    "\n",
    "#### 'contested' is correctly tagged as 'VERB'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
